name: SonarQube Analysis and Deployment

on:
  push:
    branches:
      - main

jobs:
  sonarQubeAnalysis:
    runs-on: ubuntu-latest

    steps:
      # Checkout the repository
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.x'

      # Install dependencies
      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install nbconvert pytest pytest-cov coverage

      # Convert .ipynb notebooks to .py
      - name: Convert Notebooks to Python scripts
        run: |
          jupyter nbconvert --to script notebooks/*.ipynb --output-dir notebooks
          # Rename .txt files to .py
          for file in notebooks/*.txt; do
            mv "$file" "${file%.txt}.py"
          done
          # Verify the result
          ls notebooks

      # Set PYTHONPATH
      - name: Set PYTHONPATH
        run: |
          echo "PYTHONPATH=$(pwd):$(pwd)/notebooks" >> $GITHUB_ENV

      # Run Tests with Coverage
      - name: Run Tests with Coverage
        run: |
          pytest tests --cov=notebooks --cov-report=xml

      # Run SonarScanner
      - name: Run SonarScanner
        run: |
          wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-4.8.0.2856-linux.zip
          unzip sonar-scanner-cli-4.8.0.2856-linux.zip
          export PATH="$PATH:$(pwd)/sonar-scanner-4.8.0.2856-linux/bin"
          sonar-scanner -Dsonar.projectKey=databricks_project \
                        -Dsonar.projectName=DatabricksProject \
                        -Dsonar.projectVersion=1.0 \
                        -Dsonar.sources=notebooks \
                        -Dsonar.python.coverage.reportPaths=coverage.xml \
                        -Dsonar.python.version=3.x \
                        -Dsonar.host.url=http://20.55.75.25:9000 \
                        -Dsonar.login=${{ secrets.SONAR_TOKEN }}

  deployToDatabricksDev:
    runs-on: ubuntu-latest
    needs: sonarQubeAnalysis
    environment: DEV_WORKSPACE_NAME
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Install Databricks CLI
      - name: Install Databricks CLI
        run: |
          pip install databricks-cli
          az extension add --name databricks

      # Configure Databricks CLI for Dev
      - name: Configure Databricks CLI for Dev
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_DEV_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_DEV_TOKEN }}
        run: |
          mkdir -p ~/.databricks
          echo "[DEFAULT]" > ~/.databricks/config
          echo "host = $DATABRICKS_HOST" >> ~/.databricks/config
          echo "token = $DATABRICKS_TOKEN" >> ~/.databricks/config

      - name: Deploy Notebooks to Dev Environment
        env:
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          DEV_WORKSPACE_NAME: ${{ secrets.DEV_WORKSPACE_NAME }}
          DEV_RESOURCE_GROUP: ${{ secrets.DEV_RESOURCE_GROUP }}
        run: |
          az login --service-principal --username $AZURE_CLIENT_ID --password $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID
          az account set --subscription $AZURE_SUBSCRIPTION_ID
          databricks workspace import_dir notebooks /Workspace/notebooks

  deployToDatabricksProd:
    runs-on: ubuntu-latest
    needs: deployToDatabricksDev
    environment: PROD_WORKSPACE_NAME
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      # Install Databricks CLI
      - name: Install Databricks CLI
        run: |
          pip install databricks-cli
          az extension add --name databricks

      # Configure Databricks CLI for Prod
      - name: Configure Databricks CLI for Prod
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_PROD_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_PROD_TOKEN }}
        run: |
          mkdir -p ~/.databricks
          echo "[DEFAULT]" > ~/.databricks/config
          echo "host = $DATABRICKS_HOST" >> ~/.databricks/config
          echo "token = $DATABRICKS_TOKEN" >> ~/.databricks/config

      - name: Deploy Notebooks to Prod Environment
        env:
          AZURE_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
          AZURE_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
          AZURE_CLIENT_SECRET: ${{ secrets.AZURE_CLIENT_SECRET }}
          AZURE_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
          PROD_WORKSPACE_NAME: ${{ secrets.PROD_WORKSPACE_NAME }}
          PROD_RESOURCE_GROUP: ${{ secrets.PROD_RESOURCE_GROUP }}
        run: |
          az login --service-principal --username $AZURE_CLIENT_ID --password $AZURE_CLIENT_SECRET --tenant $AZURE_TENANT_ID
          az account set --subscription $AZURE_SUBSCRIPTION_ID
          databricks workspace import_dir notebooks /Workspace/notebooks
